"""
Bayesian-AI - Learning Dashboard Generator
Generates a consolidated Jupyter notebook for Preflight Checks, System Debugging, and Learning Simulations.
"""
import json
import os

notebook = {
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Bayesian-AI Master Dashboard\n",
    "\n",
    "**Objective:** Consolidated interface for System Verification, Debugging, and Learning Simulations.\n",
    "**Workflow:** Preflight -> Component Check -> Data Verification -> Simulation -> Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preflight & Environment Checks ‚úàÔ∏è\n",
    "Verify Operational Mode, Environment, and CUDA Availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "from numba import cuda\n",
    "\n",
    "# Add root to path\n",
    "current_dir = Path(os.getcwd())\n",
    "project_root = current_dir\n",
    "while not (project_root / 'requirements.txt').exists():\n",
    "    parent = project_root.parent\n",
    "    if parent == project_root:\n",
    "        break\n",
    "    project_root = parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "print(f\"Project Root: {project_root}\")\n",
    "\n",
    "from config.settings import OPERATIONAL_MODE, RAW_DATA_PATH\n",
    "from training.orchestrator import get_data_source, load_data_from_directory\n",
    "\n",
    "# 1. Check Operational Mode\n",
    "print(f\"\\nOperational Mode: {OPERATIONAL_MODE}\")\n",
    "if OPERATIONAL_MODE != \"LEARNING\":\n",
    "    print(\"üî¥ WARNING: System should be in 'LEARNING' mode for this dashboard.\")\n",
    "else:\n",
    "    print(\"üü¢ Mode Checked\")\n",
    "\n",
    "# 2. Check CUDA (Strict)\n",
    "try:\n",
    "    if cuda.is_available():\n",
    "        print(f\"üü¢ CUDA Available: {cuda.detect()}\")\n",
    "        device = cuda.get_current_device()\n",
    "        print(f\"   Device: {device.name}\")\n",
    "    else:\n",
    "        print(\"üî¥ CUDA Not Available. System requires GPU.\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ CUDA Check Failed: {e}\")\n",
    "\n",
    "# 3. Run Deep Audit\n",
    "import cuda_modules.hardened_verification as hv\n",
    "print(\"\\nRunning 3-Stage CUDA Audit (Handshake -> Injection -> Handoff)...\")\n",
    "try:\n",
    "    # This validates the CPU->GPU injection path and pure GPU handoff\n",
    "    success = hv.run_audit()\n",
    "    if success:\n",
    "        print(\"üü¢ Audit Passed! (See CUDA_Debug.log)\")\n",
    "    else:\n",
    "        print(\"üî¥ Audit Failed! (See CUDA_Debug.log)\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ Execution Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Component Verification ‚öôÔ∏è\n",
    "Verify initialization of critical modules with **Strict GPU Enforcement**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.state_vector import StateVector\n",
    "from core.bayesian_brain import BayesianBrain\n",
    "from core.layer_engine import LayerEngine\n",
    "from cuda_modules.velocity_gate import CUDAVelocityGate\n",
    "from cuda_modules.pattern_detector import CUDAPatternDetector\n",
    "\n",
    "print(\"--- Component Status ---\")\n",
    "\n",
    "# 1. StateVector\n",
    "try:\n",
    "    sv = StateVector.null_state()\n",
    "    assert hash(sv) is not None\n",
    "    print(\"üü¢ StateVector: Operational\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ StateVector: Failed ({e})\")\n",
    "\n",
    "# 2. BayesianBrain\n",
    "try:\n",
    "    bb = BayesianBrain()\n",
    "    print(\"üü¢ BayesianBrain: Initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ BayesianBrain: Failed ({e})\")\n",
    "\n",
    "# 3. LayerEngine (GPU ONLY)\n",
    "try:\n",
    "    if cuda.is_available():\n",
    "        # Explicitly requesting GPU. If fallback logic exists in class, we want to ensure\n",
    "        # we are using the GPU path.\n",
    "        le = LayerEngine(use_gpu=True)\n",
    "        if le.use_gpu:\n",
    "             print(\"üü¢ LayerEngine: Initialized (GPU Active)\")\n",
    "        else:\n",
    "             print(\"üî¥ LayerEngine: Fallback to CPU detected (Unexpected)\")\n",
    "    else:\n",
    "        print(\"üî¥ LayerEngine: Skipped (No CUDA)\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ LayerEngine: Failed ({e})\")\n",
    "\n",
    "# 4. CUDA VelocityGate (GPU ONLY)\n",
    "try:\n",
    "    if cuda.is_available():\n",
    "        vg = CUDAVelocityGate(use_gpu=True)\n",
    "        print(f\"üü¢ VelocityGate: Initialized (GPU={vg.use_gpu})\")\n",
    "    else:\n",
    "        print(\"üî¥ VelocityGate: Skipped (No CUDA)\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ VelocityGate: Failed ({e})\")\n",
    "\n",
    "# 5. Pattern Detector (GPU ONLY)\n",
    "try:\n",
    "    if cuda.is_available():\n",
    "        pd_cuda = CUDAPatternDetector(use_gpu=True)\n",
    "        print(f\"üü¢ PatternDetector: Initialized (GPU={pd_cuda.use_gpu})\")\n",
    "    else:\n",
    "         print(\"üî¥ PatternDetector: Skipped (No CUDA)\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ PatternDetector: Failed ({e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Setup & Verification üìä\n",
    "Ensure `DATA/RAW` contains valid data and visualize a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(f\"Loading data from {RAW_DATA_PATH}...\")\n",
    "    # Load full dataset into memory for slicing\n",
    "    full_data = load_data_from_directory(str(project_root / RAW_DATA_PATH))\n",
    "    \n",
    "    print(f\"üü¢ Data Loaded! Rows: {len(full_data)}\")\n",
    "    \n",
    "    # Ensure timestamp conversion\n",
    "    if 'timestamp' in full_data.columns:\n",
    "        full_data['datetime'] = pd.to_datetime(full_data['timestamp'], unit='s' if full_data['timestamp'].dtype == 'float64' else None)\n",
    "    else:\n",
    "        # Fallback if index is datetime\n",
    "        full_data['datetime'] = full_data.index\n",
    "    \n",
    "    # Show date range\n",
    "    min_date = full_data['datetime'].min()\n",
    "    max_date = full_data['datetime'].max()\n",
    "    print(f\"Date Range: {min_date} to {max_date}\")\n",
    "    \n",
    "    # Visualize Sample\n",
    "    plot_df = full_data.head(1000)\n",
    "    fig = go.Figure(data=[go.Candlestick(x=plot_df['datetime'],\n",
    "                open=plot_df['price'], high=plot_df['price'],\n",
    "                low=plot_df['price'], close=plot_df['price'])])\n",
    "    fig.update_layout(title='Price Sample (First 1000 ticks)', xaxis_rangeslider_visible=False)\n",
    "    fig.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"üî¥ Data Load Failed: {e}\")\n",
    "    full_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI Helper: Simulation Monitor\n",
    "class SimulationMonitor:\n",
    "    def __init__(self, title=\"Simulation Progress\", max_steps=100):\n",
    "        # Widgets\n",
    "        self.lbl_title = widgets.HTML(f\"<b>{title}</b>\")\n",
    "        self.progress = widgets.IntProgress(value=0, min=0, max=max_steps, description='Progress:', bar_style='info')\n",
    "        self.lbl_status = widgets.Label(value=\"Initializing...\")\n",
    "        self.log_area = widgets.Output(layout={'border': '1px solid #ccc', 'height': '200px', 'overflow_y': 'scroll'})\n",
    "        \n",
    "        # Layout Container (Pop-up style)\n",
    "        self.container = widgets.VBox(\n",
    "            [self.lbl_title, self.progress, self.lbl_status, self.log_area],\n",
    "            layout=widgets.Layout(\n",
    "                border='2px solid #007bff',\n",
    "                padding='10px',\n",
    "                margin='10px 0',\n",
    "                background_color='#f8f9fa',\n",
    "                width='100%'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def show(self):\n",
    "        display(self.container)\n",
    "        \n",
    "    def log(self, message):\n",
    "        with self.log_area:\n",
    "            print(message)\n",
    "            \n",
    "    def update_progress(self, value, status=None):\n",
    "        self.progress.value = value\n",
    "        if status:\n",
    "            self.lbl_status.value = status\n",
    "            \n",
    "    def complete(self, success=True):\n",
    "        self.progress.value = self.progress.max\n",
    "        self.progress.bar_style = 'success' if success else 'danger'\n",
    "        self.lbl_status.value = \"Complete\" if success else \"Failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick Learn: 3 Discrete Day Simulation üé≤\n",
    "Randomly select 3 days and run isolated learning simulations to verify logic and win rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from training.orchestrator import TrainingOrchestrator\n",
    "\n",
    "def run_quick_learn(monitor, verbose=False):\n",
    "    if full_data is None:\n",
    "        monitor.log(\"üî¥ No data loaded.\")\n",
    "        monitor.complete(False)\n",
    "        return\n",
    "\n",
    "    # Identify unique days\n",
    "    monitor.log(\"Identifying unique days...\")\n",
    "    unique_days = full_data['datetime'].dt.date.unique()\n",
    "    \n",
    "    if len(unique_days) < 3:\n",
    "        monitor.log(f\"üü° Not enough data for 3 discrete days. Found: {len(unique_days)}\")\n",
    "        selected_days = unique_days\n",
    "    else:\n",
    "        selected_days = sorted(random.sample(list(unique_days), 3))\n",
    "    \n",
    "    monitor.log(f\"Selected Days: {selected_days}\")\n",
    "    \n",
    "    results = []\n",
    "    total_steps = len(selected_days)\n",
    "    monitor.progress.max = total_steps\n",
    "    \n",
    "    for i, day in enumerate(selected_days):\n",
    "        monitor.update_progress(i, f\"Simulating {day}...\")\n",
    "        monitor.log(f\"--- Simulating {day} ---\")\n",
    "        \n",
    "        day_mask = full_data['datetime'].dt.date == day\n",
    "        day_data = full_data[day_mask].copy()\n",
    "        \n",
    "        # Initialize Orchestrator for this chunk\n",
    "        debug_path = f'debug_outputs/quick_learn/debug_{day}.log' if verbose else None\n",
    "        if verbose:\n",
    "             monitor.log(f\"üìù Logging to {debug_path}\")\n",
    "\n",
    "        orch = TrainingOrchestrator(\n",
    "            asset_ticker='MNQ', \n",
    "            data=day_data, \n",
    "            output_dir='debug_outputs/quick_learn',\n",
    "            verbose=verbose,\n",
    "            debug_file=debug_path\n",
    "        )\n",
    "        \n",
    "        # Run 1 iteration\n",
    "        metrics = orch.run_training(iterations=1, params={'mode': 'quick_learn'})\n",
    "        metrics['date'] = day\n",
    "        results.append(metrics)\n",
    "        \n",
    "        monitor.log(f\"Day Result: PnL=${metrics['pnl']:.2f}, WR={metrics['win_rate']:.1%}\")\n",
    "        \n",
    "    monitor.complete(True)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n=== Quick Learn Summary ===\")\n",
    "    res_df = pd.DataFrame(results)\n",
    "    display(res_df[['date', 'total_trades', 'win_rate', 'pnl']])\n",
    "\n",
    "chk_verbose = widgets.Checkbox(value=False, description='Enable Verbose Logging')\n",
    "btn_quick = widgets.Button(description=\"Run 3-Day Sim\", button_style='info')\n",
    "\n",
    "def on_quick_click(b):\n",
    "    # Create and show monitor\n",
    "    mon = SimulationMonitor(\"Quick Learn Simulation\")\n",
    "    mon.show()\n",
    "    run_quick_learn(mon, verbose=chk_verbose.value)\n",
    "\n",
    "btn_quick.on_click(on_quick_click)\n",
    "display(widgets.HBox([btn_quick, chk_verbose]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Full Learning Cycle üöÄ\n",
    "Execute the full training pipeline on all available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_full_training(iterations=10, monitor=None):\n",
    "    if monitor:\n",
    "        monitor.log(f\"Starting Full Training ({iterations} iterations)...\")\n",
    "    \n",
    "    cmd = [\n",
    "        \"python\", \"training/orchestrator.py\",\n",
    "        \"--data-dir\", \"DATA/RAW\",\n",
    "        \"--iterations\", str(iterations),\n",
    "        \"--output\", \"models/\"\n",
    "    ]\n",
    "    \n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "    \n",
    "    # Approximate progress based on output lines or just spin\n",
    "    monitor.progress.max = iterations\n",
    "    current_iter = 0\n",
    "    \n",
    "    while True:\n",
    "        line = process.stdout.readline()\n",
    "        if not line and process.poll() is not None:\n",
    "            break\n",
    "        if line:\n",
    "            clean_line = line.strip()\n",
    "            monitor.log(clean_line)\n",
    "            if \"Iter\" in clean_line:\n",
    "                current_iter += 1\n",
    "                monitor.update_progress(current_iter, f\"Running Iteration {current_iter}/{iterations}\")\n",
    "            \n",
    "    if process.returncode == 0:\n",
    "        monitor.complete(True)\n",
    "        monitor.log(\"‚úÖ Full Training Complete!\")\n",
    "    else:\n",
    "        monitor.complete(False)\n",
    "        monitor.log(f\"‚ùå Training Failed (Code {process.returncode})\")\n",
    "\n",
    "btn_full = widgets.Button(description=\"Execute Full Learn\", button_style='danger')\n",
    "\n",
    "def on_full_click(b):\n",
    "    mon = SimulationMonitor(\"Full Learning Cycle\", max_steps=10)\n",
    "    mon.show()\n",
    "    run_full_training(iterations=10, monitor=mon)\n",
    "\n",
    "btn_full.on_click(on_full_click)\n",
    "display(btn_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Result Analysis & Profiling üìà\n",
    "Analyze the probability tables and performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import timeit\n",
    "import itertools\n",
    "\n",
    "def inspect_table(path, title):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"‚ö™ {title}: File not found ({path})\")\n",
    "        return\n",
    "    \n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    table = data['table'] if isinstance(data, dict) and 'table' in data else data.table\n",
    "    print(f\"üü¢ {title}: {len(table)} states learned.\")\n",
    "    \n",
    "    # Convert to DataFrame for deep dive\n",
    "    records = []\n",
    "    for state, stats in table.items():\n",
    "        total = stats['total']\n",
    "        wins = stats['wins']\n",
    "        if total > 0:\n",
    "            records.append({\n",
    "                'total': total,\n",
    "                'wins': wins,\n",
    "                'win_rate': wins/total,\n",
    "                'L1': state.L1_bias,\n",
    "                'L5': state.L5_trend\n",
    "            })\n",
    "    \n",
    "    if records:\n",
    "        df_stats = pd.DataFrame(records)\n",
    "        # Win Rate vs Sample Size\n",
    "        fig = px.scatter(df_stats, x='total', y='win_rate', title=f'{title}: Win Rate vs Sample Size',\n",
    "                          hover_data=['L1', 'L5'])\n",
    "        fig.show()\n",
    "\n",
    "print(\"--- Model Status ---\")\n",
    "inspect_table('debug_outputs/quick_learn/probability_table.pkl', \"Quick Learn Temp\")\n",
    "inspect_table('models/probability_table.pkl', \"Main Model\")\n",
    "\n",
    "print(\"\\n--- Performance Profiling ---\")\n",
    "print(\"Benchmarking StateVector Hashing...\")\n",
    "setup_code = \"from core.state_vector import StateVector; sv = StateVector.null_state()\"\n",
    "t = timeit.timeit(\"hash(sv)\", setup=setup_code, number=100000)\n",
    "print(f\"Create & Hash 100k states: {t:.4f}s\")\n",
    "\n",
    "print(\"\\n--- DOE Simulation Preview ---\")\n",
    "param_grid = {\n",
    "    'min_prob': [0.70, 0.75, 0.80, 0.85],\n",
    "    'min_conf': [0.20, 0.30, 0.40],\n",
    "    'stop_loss': [10, 20, 30],\n",
    "    'kill_zones': ['tight', 'wide']\n",
    "}\n",
    "keys, values = zip(*param_grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "print(f\"Total Parameter Combinations: {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Utilities \ud83d\udee0\ufe0f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def clean_pycache():\n",
    "    print(\"Cleaning __pycache__...\")\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk('.'):\n",
    "        for d in dirs:\n",
    "            if d == '__pycache__':\n",
    "                shutil.rmtree(os.path.join(root, d))\n",
    "                count += 1\n",
    "    print(f\"Removed {count} directories.\")\n",
    "\n",
    "btn_clean = widgets.Button(description=\"Clear PyCache\")\n",
    "btn_clean.on_click(lambda b: clean_pycache())\n",
    "display(btn_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

with open('notebooks/learning_dashboard.ipynb', 'w') as f:
    json.dump(notebook, f, indent=1)

print("Notebook generated successfully: notebooks/learning_dashboard.ipynb")
