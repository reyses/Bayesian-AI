{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SECTION 1: IMPORTS & SETUP\n",
                "Clear all legacy imports.\n",
                "Import updated modules and set plot style."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import pickle\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Add project root to path\n",
                "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
                "if project_root not in sys.path:\n",
                "    sys.path.append(project_root)\n",
                "\n",
                "from core.quantum_field_engine import QuantumFieldEngine  # For physics verifications\n",
                "from training.fractal_clustering import FractalClusteringEngine\n",
                "from training.monte_carlo_engine import ComboResult, IterationResult, TradeResult\n",
                "\n",
                "plt.style.use('dark_background')\n",
                "%matplotlib inline\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SECTION 2: LOAD STATE\n",
                "Load the Pickle files. Handle FileNotFoundError gracefully."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CHECKPOINT_DIR = '../checkpoints'\n",
                "MC_STATE_PATH = os.path.join(CHECKPOINT_DIR, 'mc_sweep_state.pkl')\n",
                "PATTERN_LIB_PATH = os.path.join(CHECKPOINT_DIR, 'pattern_library.pkl')\n",
                "TRAINING_LOG_PATH = os.path.join(CHECKPOINT_DIR, 'training_log.csv')\n",
                "\n",
                "results_db = {}\n",
                "pattern_library = {}\n",
                "\n",
                "# Load Monte Carlo State\n",
                "if os.path.exists(MC_STATE_PATH):\n",
                "    try:\n",
                "        with open(MC_STATE_PATH, 'rb') as f:\n",
                "            data = pickle.load(f)\n",
                "            results_db = data.get('results_db', {})\n",
                "            print(f\"Loaded results_db with {len(results_db)} entries.\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error loading {MC_STATE_PATH}: {e}\")\n",
                "else:\n",
                "    print(f\"WARNING: {MC_STATE_PATH} not found. Ensure training/simulation has run.\")\n",
                "\n",
                "# Load Pattern Library\n",
                "if os.path.exists(PATTERN_LIB_PATH):\n",
                "    try:\n",
                "        with open(PATTERN_LIB_PATH, 'rb') as f:\n",
                "            pattern_library = pickle.load(f)\n",
                "            print(f\"Loaded pattern_library with {len(pattern_library)} templates.\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error loading {PATTERN_LIB_PATH}: {e}\")\n",
                "else:\n",
                "    print(f\"WARNING: {PATTERN_LIB_PATH} not found.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SECTION 3: VISUALIZATION 1 - THE PHYSICS MANIFOLD\n",
                "Goal: See where our specialized \"Templates\" live in physics space.\n",
                "X-Axis: Z-Score (Mean Reversion pressure).\n",
                "Y-Axis: Momentum (Trend pressure).\n",
                "Size: Member Count.\n",
                "Color: Win Rate or Cluster ID."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not pattern_library:\n",
                "    print(\"No patterns to visualize.\")\n",
                "else:\n",
                "    data = []\n",
                "    for tid, info in pattern_library.items():\n",
                "        centroid = info.get('centroid')\n",
                "        if centroid is None:\n",
                "            continue\n",
                "        \n",
                "        # Centroid: [Z-Score, Velocity, Momentum, Coherence, ...]\n",
                "        z_score = centroid[0]\n",
                "        momentum = centroid[2]\n",
                "        member_count = info.get('member_count', 10)\n",
                "        \n",
                "        # Try to find win rate from results_db if available\n",
                "        win_rate = 0.0\n",
                "        # We check if this template has results in results_db\n",
                "        # results_db is keyed by (tid, tf)\n",
                "        # We'll take the best win rate across timeframes for coloring\n",
                "        template_results = [res for key, res in results_db.items() if key[0] == tid]\n",
                "        if template_results:\n",
                "            win_rate = max([r.best_win_rate for r in template_results])\n",
                "        \n",
                "        data.append({\n",
                "            'Template_ID': tid,\n",
                "            'Z_Score': z_score,\n",
                "            'Momentum': momentum,\n",
                "            'Member_Count': member_count,\n",
                "            'Win_Rate': win_rate\n",
                "        })\n",
                "    \n",
                "    df_physics = pd.DataFrame(data)\n",
                "    \n",
                "    plt.figure(figsize=(12, 8))\n",
                "    scatter = plt.scatter(\n",
                "        df_physics['Z_Score'], \n",
                "        df_physics['Momentum'], \n",
                "        s=df_physics['Member_Count'] * 2,  # Scale size\n",
                "        c=df_physics['Win_Rate'], \n",
                "        cmap='viridis', \n",
                "        alpha=0.7,\n",
                "        edgecolors='w'\n",
                "    )\n",
                "    \n",
                "    plt.colorbar(scatter, label='Max Win Rate')\n",
                "    plt.title('Physics Manifold: Template Distribution (Z-Score vs Momentum)')\n",
                "    plt.xlabel('Z-Score (Mean Reversion Pressure)')\n",
                "    plt.ylabel('Momentum (Trend Pressure)')\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SECTION 4: VISUALIZATION 2 - THE FISSION REPORT\n",
                "Goal: Validate that \"Cluster Fission\" actually worked.\n",
                "Identify Templates that share the same \"Base ID\" and plot their PnL distributions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Helper to identify base ID\n",
                "# Assuming ID format might be integer or string. If integer, we might need a mapping or check string similarity.\n",
                "# If we don't have explicit hierarchy, we can group by numeric proximity or skip if IDs are just sequential.\n",
                "# User prompt example: 42 -> 420, 421. This implies string prefix or specific generation logic.\n",
                "# Let's try to group by string prefix of length - 1 if length > 2?\n",
                "# Or look for IDs that share a common prefix.\n",
                "\n",
                "def get_base_id(tid):\n",
                "    s_tid = str(tid)\n",
                "    if len(s_tid) > 2:\n",
                "        return s_tid[:-1]\n",
                "    return s_tid\n",
                "\n",
                "if not results_db:\n",
                "    print(\"No simulation results to analyze for fission.\")\n",
                "else:\n",
                "    # Group results by potential parent\n",
                "    groups = {}\n",
                "    for key, result in results_db.items():\n",
                "        tid = key[0]\n",
                "        base = get_base_id(tid)\n",
                "        if base not in groups:\n",
                "            groups[base] = []\n",
                "        groups[base].append((tid, result))\n",
                "    \n",
                "    # Filter for interesting groups (more than 1 child)\n",
                "    fission_groups = {k: v for k, v in groups.items() if len(set(x[0] for x in v)) > 1}\n",
                "    \n",
                "    # Select top group by total trades or PnL to visualize\n",
                "    if fission_groups:\n",
                "        # Pick the group with most variations\n",
                "        best_base = max(fission_groups, key=lambda k: len(fission_groups[k]))\n",
                "        items = fission_groups[best_base]\n",
                "        \n",
                "        # Prepare data for box plot\n",
                "        plot_data = []\n",
                "        labels = []\n",
                "        \n",
                "        print(f\"Visualizing Fission Group for Base ID: {best_base} (Templates: {set(x[0] for x in items)})\")\n",
                "        \n",
                "        for tid, res in items:\n",
                "            # Extract PnLs from all iterations (or best iteration trades)\n",
                "            # We'll use the trades from the best iteration\n",
                "            if res.iterations:\n",
                "                best_iter = max(res.iterations, key=lambda i: i.total_pnl)\n",
                "                pnls = [t.pnl for t in best_iter.trades]\n",
                "                if pnls:\n",
                "                    plot_data.append(pnls)\n",
                "                    labels.append(f\"TID {tid}\\n({res.timeframe})\")\n",
                "        \n",
                "        if plot_data:\n",
                "            plt.figure(figsize=(14, 6))\n",
                "            plt.boxplot(plot_data, labels=labels)\n",
                "            plt.title(f'PnL Distribution Comparison: Fission Group {best_base}')\n",
                "            plt.ylabel('Trade PnL ($)')\n",
                "            plt.grid(True, alpha=0.3)\n",
                "            plt.xticks(rotation=45)\n",
                "            plt.show()\n",
                "        else:\n",
                "            print(\"No trades found in this group to plot.\")\n",
                "    else:\n",
                "        print(\"No obvious fission groups found (based on ID prefix heuristic).\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SECTION 5: VISUALIZATION 3 - MONTE CARLO HEATMAP\n",
                "Goal: Identify the \"Golden Timeframes\".\n",
                "Highlight combinations with Sharpe > 2.0."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not results_db:\n",
                "    print(\"No results to visualize.\")\n",
                "else:\n",
                "    heatmap_data = []\n",
                "    \n",
                "    for (tid, tf), res in results_db.items():\n",
                "        # Calculate Sharpe\n",
                "        sharpe = 0.0\n",
                "        if res.iterations:\n",
                "            best_iter = max(res.iterations, key=lambda i: i.total_pnl)\n",
                "            pnls = [t.pnl for t in best_iter.trades]\n",
                "            if len(pnls) > 1 and np.std(pnls) > 0:\n",
                "                sharpe = np.mean(pnls) / np.std(pnls)\n",
                "        \n",
                "        heatmap_data.append({\n",
                "            'Template_ID': tid,\n",
                "            'Timeframe': tf,\n",
                "            'Sharpe_Ratio': sharpe,\n",
                "            'Total_PnL': res.best_pnl\n",
                "        })\n",
                "    \n",
                "    df_hm = pd.DataFrame(heatmap_data)\n",
                "    \n",
                "    if not df_hm.empty:\n",
                "        # Pivot\n",
                "        pivot_hm = df_hm.pivot(index='Template_ID', columns='Timeframe', values='Sharpe_Ratio')\n",
                "        \n",
                "        plt.figure(figsize=(14, 10))\n",
                "        sns.heatmap(pivot_hm, annot=True, fmt=\".2f\", cmap='RdYlGn', center=0, vmin=-1, vmax=3)\n",
                "        plt.title('Monte Carlo Heatmap: Sharpe Ratio by Template & Timeframe')\n",
                "        plt.show()\n",
                "        \n",
                "        # Highlight Golden Timeframes\n",
                "        golden = df_hm[df_hm['Sharpe_Ratio'] > 2.0]\n",
                "        if not golden.empty:\n",
                "            print(\"\\nGolden Timeframes (Sharpe > 2.0):\")\n",
                "            display(golden[['Template_ID', 'Timeframe', 'Sharpe_Ratio', 'Total_PnL']].sort_values('Sharpe_Ratio', ascending=False))\n",
                "        else:\n",
                "            print(\"\\nNo Golden Timeframes (Sharpe > 2.0) found.\")\n",
                "    else:\n",
                "        print(\"DataFrame is empty.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SECTION 6: PLAYBOOK GENERATION\n",
                "Goal: Export the final \"Cheatsheet\" for the trader.\n",
                "Filter top 10 performing Templates."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not results_db:\n",
                "    print(\"No results to generate playbook.\")\n",
                "else:\n",
                "    # Flatten results\n",
                "    playbook_items = []\n",
                "    \n",
                "    for (tid, tf), res in results_db.items():\n",
                "        if not res.iterations:\n",
                "            continue\n",
                "            \n",
                "        best_iter = max(res.iterations, key=lambda i: i.total_pnl)\n",
                "        best_params = res.best_params or {}\n",
                "        \n",
                "        # Determine Type (Roche vs Structural)\n",
                "        # From pattern_library centroid z-score\n",
                "        p_type = \"Unknown\"\n",
                "        if tid in pattern_library:\n",
                "            centroid = pattern_library[tid]['centroid']\n",
                "            # z_score is usually index 0. \n",
                "            # If abs(z) > 2.0 usually Roche/Reversion, else Structural/Trend?\n",
                "            # Or check sign. The prompt says \"Type\".\n",
                "            # Let's use simple logic: Z > 2 or Z < -2 => Reversion (Roche-like), else Trend (Structural)\n",
                "            z = centroid[0]\n",
                "            if abs(z) > 2.0:\n",
                "                p_type = \"Reversion (Roche)\"\n",
                "            else:\n",
                "                p_type = \"Trend (Structural)\"\n",
                "        \n",
                "        playbook_items.append({\n",
                "            'ID': tid,\n",
                "            'Type': p_type,\n",
                "            'Best Timeframe': tf,\n",
                "            'Win Rate': res.best_win_rate,\n",
                "            'Stop (Ticks)': best_params.get('stop_loss_ticks', 'N/A'),\n",
                "            'Profit (Ticks)': best_params.get('take_profit_ticks', 'N/A'),\n",
                "            'Total PnL': res.best_pnl\n",
                "        })\n",
                "    \n",
                "    df_pb = pd.DataFrame(playbook_items)\n",
                "    \n",
                "    if not df_pb.empty:\n",
                "        # Filter top 10 by PnL\n",
                "        top_10 = df_pb.sort_values('Total PnL', ascending=False).head(10)\n",
                "        \n",
                "        print(\"TOP 10 TRADING PLAYBOOK\")\n",
                "        display(top_10)\n",
                "    else:\n",
                "        print(\"No profitable strategies found.\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}