{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Bayesian-AI Dashboard\n",
    "\n",
    "**Objective:** Consolidated interface for System Verification, Debugging, and Full Learning Cycle.\n",
    "**Sections:**\n",
    "1. Preflight & Environment Checks (Deep Audit)\n",
    "2. Data Pipeline Test\n",
    "3. Core Component Tests\n",
    "4. Quick Learn (3-Day Simulation)\n",
    "5. Mini Training Run (5 Iterations)\n",
    "6. Full Learning Cycle (Production Run)\n",
    "7. Result Analysis & Visualization\n",
    "8. Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preflight & Environment Checks ‚úàÔ∏è\n",
    "Verify Python environment, CUDA availability, and run Deep Audit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "from numba import cuda\n",
    "\n",
    "# Add root to path\n",
    "current_dir = Path(os.getcwd())\n",
    "project_root = current_dir\n",
    "while not (project_root / 'requirements.txt').exists():\n",
    "    parent = project_root.parent\n",
    "    if parent == project_root:\n",
    "        break\n",
    "    project_root = parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "print(f\"Project Root: {project_root}\")\n",
    "\n",
    "import importlib\n",
    "import config.settings\n",
    "importlib.reload(config.settings)\n",
    "from config.settings import OPERATIONAL_MODE, RAW_DATA_PATH, ANCHOR_DATE\n",
    "import cuda_modules.hardened_verification as hv\n",
    "from training.orchestrator import TrainingOrchestrator, load_data_from_directory, get_data_source\n",
    "\n",
    "# 1. Check Operational Mode\n",
    "print(f\"\\nOperational Mode: {OPERATIONAL_MODE}\")\n",
    "\n",
    "# 2. Check CUDA\n",
    "CUDA_LOCKED = False\n",
    "try:\n",
    "    if cuda.is_available():\n",
    "        print(f\"üü¢ CUDA Available: {cuda.detect()}\")\n",
    "        device = cuda.get_current_device()\n",
    "        print(f\"   Device: {device.name}\")\n",
    "        CUDA_LOCKED = True\n",
    "    else:\n",
    "        print(\"üî¥ CUDA Not Available. System running in CPU mode.\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ CUDA Check Failed: {e}\")\n",
    "\n",
    "print(f\"üîí CUDA Locked Mode: {CUDA_LOCKED}\")\n",
    "\n",
    "# 3. Deep Audit\n",
    "print(\"\\n--- Deep Audit ---\")\n",
    "try:\n",
    "    if hv.run_audit():\n",
    "        print(\"üü¢ Deep Audit Passed\")\n",
    "    else:\n",
    "        print(\"üî¥ Deep Audit Failed (See CUDA_Debug.log)\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ Audit Execution Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pipeline Test üìä\n",
    "Validate loading of a single data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.utils import get_test_data_files\n",
    "\n",
    "try:\n",
    "    files = get_test_data_files()\n",
    "    \n",
    "    # Filter by Anchor Date\n",
    "    def get_date_from_filename(fname):\n",
    "        import re\n",
    "        match = re.search(r\"(\\d{8})\", fname)\n",
    "        return match.group(1) if match else \"00000000\"\n",
    "\n",
    "    anchor_str = ANCHOR_DATE.replace(\"-\", \"\")\n",
    "    \n",
    "    # Sort and Filter\n",
    "    valid_files = []\n",
    "    if files:\n",
    "        # Sort chronologically\n",
    "        files.sort(key=lambda x: get_date_from_filename(os.path.basename(x)))\n",
    "        \n",
    "        # Filter >= Anchor Date\n",
    "        valid_files = [f for f in files if get_date_from_filename(os.path.basename(f)) >= anchor_str]\n",
    "        \n",
    "        if not valid_files:\n",
    "             print(f\"‚ö†Ô∏è No files found after anchor date {ANCHOR_DATE}. Using earliest available.\")\n",
    "             valid_files = files # Fallback\n",
    "    \n",
    "    if not valid_files:\n",
    "        print(\"üî¥ No data files found.\")\n",
    "    else:\n",
    "        test_file = valid_files[0]\n",
    "        print(f\"Loading {os.path.basename(test_file)} (Anchor: {ANCHOR_DATE})...\")\n",
    "        df = get_data_source(test_file)\n",
    "        print(f\"üü¢ Load Success! Shape: {df.shape}\")\n",
    "        \n",
    "        # Store for later use\n",
    "        sample_data = df.head(1000).copy() if len(df) > 1000 else df.copy()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ Pipeline Test Failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Core Component Tests ‚öôÔ∏è\n",
    "Verify StateVector, BayesianBrain, LayerEngine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.state_vector import StateVector\n",
    "from core.bayesian_brain import BayesianBrain\n",
    "from core.layer_engine import LayerEngine\n",
    "\n",
    "print(\"--- Component Status ---\")\n",
    "\n",
    "# 1. StateVector\n",
    "try:\n",
    "    sv = StateVector.null_state()\n",
    "    assert hash(sv) is not None\n",
    "    print(\"üü¢ StateVector: Operational\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ StateVector: Failed ({e})\")\n",
    "\n",
    "# 2. BayesianBrain\n",
    "try:\n",
    "    bb = BayesianBrain()\n",
    "    print(\"üü¢ BayesianBrain: Initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ BayesianBrain: Failed ({e})\")\n",
    "\n",
    "# 3. LayerEngine\n",
    "try:\n",
    "    le = LayerEngine(use_gpu=CUDA_LOCKED)\n",
    "    print(f\"üü¢ LayerEngine: Initialized (GPU={le.use_gpu})\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ LayerEngine: Failed ({e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick Learn: 3-Day Simulation üé≤\n",
    "Randomly select 3 data files and run isolated learning simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "\n",
    "# UI Helper: Simulation Monitor\n",
    "class SimulationMonitor:\n",
    "    def __init__(self, title=\"Simulation Progress\", max_steps=100):\n",
    "        self.lbl_title = widgets.HTML(f\"<b>{title}</b>\")\n",
    "        self.progress = widgets.IntProgress(value=0, min=0, max=max_steps, description='Progress:', bar_style='info')\n",
    "        self.lbl_status = widgets.Label(value=\"Initializing...\")\n",
    "        self.log_area = widgets.Output(layout={'border': '1px solid #ccc', 'height': '200px', 'overflow_y': 'scroll'})\n",
    "        self.container = widgets.VBox(\n",
    "            [self.lbl_title, self.progress, self.lbl_status, self.log_area],\n",
    "            layout=widgets.Layout(border='2px solid #007bff', padding='10px', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "    def show(self):\n",
    "        display(self.container)\n",
    "        \n",
    "    def log(self, message):\n",
    "        with self.log_area:\n",
    "            print(message)\n",
    "            \n",
    "    def update_progress(self, value, status=None):\n",
    "        self.progress.value = value\n",
    "        if status:\n",
    "            self.lbl_status.value = status\n",
    "            \n",
    "    def complete(self, success=True):\n",
    "        self.progress.value = self.progress.max\n",
    "        self.progress.bar_style = 'success' if success else 'danger'\n",
    "        self.lbl_status.value = \"Complete\" if success else \"Failed\"\n",
    "\n",
    "def run_quick_learn(monitor, verbose=False):\n",
    "    # Find data files\n",
    "    monitor.log(\"Scanning for data files...\")\n",
    "    files = glob.glob(str(project_root / 'DATA/RAW/*.parquet')) + glob.glob(str(project_root / 'DATA/RAW/*.dbn*'))\n",
    "    \n",
    "    if not files:\n",
    "        monitor.log(\"üî¥ No data files found in DATA/RAW\")\n",
    "        monitor.complete(False)\n",
    "        return\n",
    "\n",
    "    # Filter by Anchor Date\n",
    "    def get_date_from_filename(fname):\n",
    "        import re\n",
    "        match = re.search(r\"(\\d{8})\", fname)\n",
    "        return match.group(1) if match else \"00000000\"\n",
    "\n",
    "    anchor_str = ANCHOR_DATE.replace(\"-\", \"\")\n",
    "    \n",
    "    # Sort chronologically\n",
    "    files.sort(key=lambda x: get_date_from_filename(os.path.basename(x)))\n",
    "    \n",
    "    # Filter\n",
    "    valid_files = [f for f in files if get_date_from_filename(os.path.basename(f)) >= anchor_str]\n",
    "    \n",
    "    if not valid_files:\n",
    "         monitor.log(f\"‚ö†Ô∏è No files found after {ANCHOR_DATE}. Using first 3 available.\")\n",
    "         valid_files = files\n",
    "    \n",
    "    # Select first 3 files (Deterministic)\n",
    "    selected_files = valid_files[:3]\n",
    "    monitor.log(f\"Selected {len(selected_files)} files (Anchor {ANCHOR_DATE}): {[os.path.basename(f) for f in selected_files]}\")\n",
    "    \n",
    "    monitor.progress.max = len(selected_files)\n",
    "    results = []\n",
    "    \n",
    "    for i, file_path in enumerate(selected_files):\n",
    "        monitor.update_progress(i, f\"Processing {os.path.basename(file_path)}...\")\n",
    "        monitor.log(f\"--- Loading {os.path.basename(file_path)} ---\")\n",
    "        \n",
    "        try:\n",
    "            # Load Single File\n",
    "            df = get_data_source(file_path)\n",
    "            monitor.log(f\"Loaded {len(df)} ticks.\")\n",
    "            \n",
    "            # Initialize Orchestrator\n",
    "            orch = TrainingOrchestrator(\n",
    "                asset_ticker='MNQ', \n",
    "                data=df, \n",
    "                output_dir='debug_outputs/quick_learn',\n",
    "                use_gpu=CUDA_LOCKED,\n",
    "                verbose=verbose\n",
    "            )\n",
    "            \n",
    "            # Run 1 iteration\n",
    "            metrics = orch.run_training(iterations=1, params={'mode': 'quick_learn'})\n",
    "            metrics['file'] = os.path.basename(file_path)\n",
    "            results.append(metrics)\n",
    "            monitor.log(f\"Result: PnL=${metrics['pnl']:.2f}, WR={metrics['win_rate']:.1%}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            monitor.log(f\"üî¥ Error processing file: {e}\")\n",
    "            \n",
    "    monitor.complete(True)\n",
    "    \n",
    "    # Summary\n",
    "    if results:\n",
    "        print(\"\\n=== Quick Learn Summary ===\")\n",
    "        res_df = pd.DataFrame(results)\n",
    "        display(res_df[['file', 'total_trades', 'win_rate', 'pnl']])\n",
    "\n",
    "chk_verbose = widgets.Checkbox(value=False, description='Verbose Mode')\n",
    "btn_quick = widgets.Button(description=\"Run 3-File Sim\", button_style='info')\n",
    "\n",
    "def on_quick_click(b):\n",
    "    mon = SimulationMonitor(\"Quick Learn Simulation\")\n",
    "    mon.show()\n",
    "    run_quick_learn(mon, verbose=chk_verbose.value)\n",
    "\n",
    "btn_quick.on_click(on_quick_click)\n",
    "display(widgets.HBox([btn_quick, chk_verbose]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mini Training Run (5 Iterations) üèÉ‚Äç‚ôÇÔ∏è\n",
    "Interactive 5-iteration training on sample data (loaded in Sec 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mini_training(b):\n",
    "    with out_area:\n",
    "        clear_output()\n",
    "        print(\"Initializing Mini Training (5 iterations)...\")\n",
    "        \n",
    "        if 'sample_data' not in globals():\n",
    "            print(\"üî¥ Sample data not loaded. Run Section 2 first.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            orch = TrainingOrchestrator(\n",
    "                asset_ticker='MNQ', \n",
    "                data=sample_data, \n",
    "                output_dir='debug_outputs/mini_run',\n",
    "                use_gpu=CUDA_LOCKED,\n",
    "                verbose=chk_verbose_mini.value\n",
    "            )\n",
    "            \n",
    "            res = orch.run_training(iterations=5)\n",
    "            print(\"\\nüü¢ Mini Run Complete!\")\n",
    "            print(f\"Total Trades: {res['total_trades']}\")\n",
    "            print(f\"PnL: ${res['pnl']:.2f}\")\n",
    "            print(f\"Win Rate: {res['win_rate']:.1%}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"üî¥ Training Failed: {e}\")\n",
    "\n",
    "chk_verbose_mini = widgets.Checkbox(value=False, description='Verbose Mode')\n",
    "btn_run = widgets.Button(description=\"Run 5 Iterations\", button_style='primary')\n",
    "out_area = widgets.Output()\n",
    "\n",
    "btn_run.on_click(run_mini_training)\n",
    "display(widgets.VBox([widgets.HBox([btn_run, chk_verbose_mini]), out_area]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Full Learning Cycle (Production Run) üöÄ\n",
    "Loads all available data and executes the full training loop with real-time visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Widgets for Full Run\n",
    "fig_full = go.FigureWidget()\n",
    "fig_full.add_scatter(name=\"Daily PnL\", y=[], mode='lines+markers', line=dict(color='green'))\n",
    "fig_full.add_scatter(name=\"Avg Confidence\", y=[], mode='lines', line=dict(color='blue', dash='dot'), yaxis='y2')\n",
    "\n",
    "fig_full.update_layout(\n",
    "    title=\"Learning Progress: PnL & Confidence\",\n",
    "    xaxis_title=\"Iteration\",\n",
    "    yaxis_title=\"PnL ($)\",\n",
    "    yaxis2=dict(\n",
    "        title=\"Avg Confidence\",\n",
    "        overlaying='y',\n",
    "        side='right',\n",
    "        range=[0, 1]\n",
    "    ),\n",
    "    height=500,\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "\n",
    "progress_bar_full = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Progress:',\n",
    "    bar_style='info',\n",
    "    style={'bar_color': '#00ff00'},\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "status_label_full = widgets.Label(value=\"Ready to start full training.\")\n",
    "stats_output_full = widgets.Output()\n",
    "\n",
    "def update_dashboard_full(metrics):\n",
    "    # Update Charts\n",
    "    with fig_full.batch_update():\n",
    "        fig_full.data[0].y = list(fig_full.data[0].y) + [metrics['pnl']]\n",
    "        fig_full.data[1].y = list(fig_full.data[1].y) + [metrics['average_confidence']]\n",
    "        fig_full.data[0].x = list(range(1, len(fig_full.data[0].y) + 1))\n",
    "        fig_full.data[1].x = list(range(1, len(fig_full.data[1].y) + 1))\n",
    "\n",
    "    # Update Progress\n",
    "    progress_bar_full.value = metrics['iteration']\n",
    "    progress_bar_full.max = metrics['total_iterations']\n",
    "    \n",
    "    status_label_full.value = f\"Iter {metrics['iteration']}/{metrics['total_iterations']} | PnL: ${metrics['pnl']:.2f} | WR: {metrics['win_rate']:.1%} | Conf: {metrics['average_confidence']:.2f}\"\n",
    "\n",
    "ITERATIONS_DEFAULT = 50\n",
    "btn_start_full = widgets.Button(description=\"Start Full Training\", button_style='success', icon='play')\n",
    "\n",
    "def start_full_training(b):\n",
    "    btn_start_full.disabled = True\n",
    "    status_label_full.value = \"Loading All Data...\"\n",
    "    with stats_output_full:\n",
    "        clear_output()\n",
    "    \n",
    "    try:\n",
    "        # Check if DATA/RAW exists\n",
    "        data_path = os.path.join(project_root, 'DATA', 'RAW')\n",
    "        if not os.path.exists(data_path):\n",
    "             # Fallback\n",
    "             data_path = 'DATA/RAW'\n",
    "        \n",
    "        print(f\"Loading data from: {data_path}...\")\n",
    "        file_paths = load_data_from_directory(data_path)\n",
    "        dfs = []\n",
    "        for fp in file_paths:\n",
    "            try:\n",
    "                dfs.append(get_data_source(fp))\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {fp}: {e}\")\n",
    "        \n",
    "        if not dfs:\n",
    "            raise ValueError(\"No valid data files loaded\")\n",
    "             \n",
    "        full_data = pd.concat(dfs, ignore_index=True)\n",
    "        print(f\"üü¢ Data Loaded. Rows: {len(full_data):,}\")\n",
    "        \n",
    "        status_label_full.value = \"Initializing Orchestrator...\"\n",
    "        \n",
    "        # Clear previous chart data\n",
    "        with fig_full.batch_update():\n",
    "            fig_full.data[0].y = []\n",
    "            fig_full.data[1].y = []\n",
    "        \n",
    "        # Initialize Orchestrator\n",
    "        orch = TrainingOrchestrator(\n",
    "            asset_ticker='MNQ', \n",
    "            data=full_data, \n",
    "            output_dir='models/production_learning',\n",
    "            use_gpu=CUDA_LOCKED, # Use detected status\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        status_label_full.value = \"Training Started...\"\n",
    "        \n",
    "        # Run\n",
    "        orch.run_training(iterations=ITERATIONS_DEFAULT, on_progress=update_dashboard_full)\n",
    "        \n",
    "        status_label_full.value = \"‚úÖ Training Complete! Model Saved to models/production_learning/\"\n",
    "        progress_bar_full.bar_style = 'success'\n",
    "        \n",
    "    except Exception as e:\n",
    "        status_label_full.value = f\"‚ùå Error: {str(e)}\"\n",
    "        progress_bar_full.bar_style = 'danger'\n",
    "        with stats_output_full:\n",
    "            print(f\"Training Exception: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    finally:\n",
    "        btn_start_full.disabled = False\n",
    "\n",
    "btn_start_full.on_click(start_full_training)\n",
    "display(widgets.VBox([btn_start_full, progress_bar_full, status_label_full, fig_full, stats_output_full]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Result Analysis & Visualization üìà\n",
    "Analyze the learned probability tables and visualize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def inspect_table(path, title):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"‚ö™ {title}: File not found ({path})\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Loading {path}...\")\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Handle both raw dict and BayesianBrain object\n",
    "        table = data['table'] if isinstance(data, dict) and 'table' in data else getattr(data, 'table', {})\n",
    "        \n",
    "        print(f\"üü¢ {title}: {len(table)} states learned.\")\n",
    "        \n",
    "        # Convert to DF\n",
    "        records = []\n",
    "        for state, stats in table.items():\n",
    "            total = stats['total']\n",
    "            wins = stats['wins']\n",
    "            if total > 0:\n",
    "                records.append({\n",
    "                    'total': total,\n",
    "                    'wins': wins,\n",
    "                    'win_rate': wins/total,\n",
    "                    'L1': state.L1_bias,\n",
    "                    'L5': state.L5_trend\n",
    "                })\n",
    "        \n",
    "        if records:\n",
    "            df_stats = pd.DataFrame(records)\n",
    "            fig = px.scatter(df_stats, x='total', y='win_rate', \n",
    "                             title=f'{title}: Win Rate vs Sample Size',\n",
    "                             hover_data=['L1', 'L5'])\n",
    "            fig.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing table: {e}\")\n",
    "\n",
    "btn_analyze = widgets.Button(description=\"Analyze Models\")\n",
    "btn_analyze.on_click(lambda b: (\n",
    "    inspect_table('debug_outputs/quick_learn/probability_table.pkl', \"Quick Learn Temp\"),\n",
    "    inspect_table('models/probability_table.pkl', \"Main Model\"),\n",
    "    inspect_table('models/production_learning/probability_table.pkl', \"Production Model\"),\n",
    "    inspect_table('debug_outputs/mini_run/probability_table.pkl', \"Mini Run\")\n",
    "))\n",
    "display(btn_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Module Integration\n",
    "print(\"\\n--- Visualization Module Integration ---\")\n",
    "try:\n",
    "    from visualization.visualization_module import plot_training_results\n",
    "    \n",
    "    # Dropdown to select model to visualize\n",
    "    model_options = [\n",
    "        ('Production Model', 'models/production_learning/probability_table.pkl'),\n",
    "        ('Main Model', 'models/probability_table.pkl'),\n",
    "        ('Quick Learn', 'debug_outputs/quick_learn/probability_table.pkl'),\n",
    "        ('Mini Run', 'debug_outputs/mini_run/probability_table.pkl')\n",
    "    ]\n",
    "    \n",
    "    dropdown_model = widgets.Dropdown(\n",
    "        options=model_options,\n",
    "        description='Select Model:',\n",
    "    )\n",
    "    \n",
    "    btn_viz = widgets.Button(description=\"Visualize Results\", button_style='info')\n",
    "    \n",
    "    def on_viz_click(b):\n",
    "        path = dropdown_model.value\n",
    "        if os.path.exists(path):\n",
    "            print(f\"Visualizing: {path}\")\n",
    "            # Note: plot_training_results uses plt.show(), which works inline in notebooks\n",
    "            plot_training_results(path)\n",
    "        else:\n",
    "            print(f\"üî¥ Model file not found: {path}\")\n",
    "            \n",
    "    btn_viz.on_click(on_viz_click)\n",
    "    display(widgets.HBox([dropdown_model, btn_viz]))\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"üî¥ Visualization module not found. Check visualization/visualization_module.py\")\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ Visualization Integration Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Utilities üõ†Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def clean_pycache():\n",
    "    print(\"Cleaning __pycache__...\")\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk('.'):\n",
    "        for d in dirs:\n",
    "            if d == '__pycache__':\n",
    "                shutil.rmtree(os.path.join(root, d))\n",
    "                count += 1\n",
    "    print(f\"Removed {count} directories.\")\n",
    "\n",
    "btn_clean = widgets.Button(description=\"Clear PyCache\")\n",
    "btn_clean.on_click(lambda b: clean_pycache())\n",
    "display(btn_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
