{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udc1e Bayesian-AI Debug Dashboard\n",
    "\n",
    "**Objective:** Interactive system validation, debugging, and performance profiling.\n",
    "**Sections:**\n",
    "1. Environment Check\n",
    "2. Data Pipeline Test\n",
    "3. Core Component Tests\n",
    "4. Mini Training Run (5 Iterations)\n",
    "5. Probability Table Analysis\n",
    "6. Performance Profiling\n",
    "7. DOE Simulation Preview\n",
    "8. Quick Fixes & Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Check \ud83d\udda5\ufe0f\n",
    "Verify Python environment, CUDA availability, and key dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "from numba import cuda\n",
    "\n",
    "# Add root to path\n",
    "current_dir = Path(os.getcwd())\n",
    "project_root = current_dir\n",
    "while not (project_root / 'requirements.txt').exists():\n",
    "    parent = project_root.parent\n",
    "    if parent == project_root:\n",
    "        break\n",
    "    project_root = parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "print(f\"Project Root: {project_root}\")\n",
    "\n",
    "from config.settings import OPERATIONAL_MODE, RAW_DATA_PATH\n",
    "\n",
    "# 1. Check Operational Mode\n",
    "print(f\"\\nOperational Mode: {OPERATIONAL_MODE}\")\n",
    "\n",
    "# 2. Check CUDA\n",
    "try:\n",
    "    if cuda.is_available():\n",
    "        print(f\"\ud83d\udfe2 CUDA Available: {cuda.detect()}\")\n",
    "        device = cuda.get_current_device()\n",
    "        print(f\"   Device: {device.name}\")\n",
    "    else:\n",
    "        print(\"\ud83d\udd34 CUDA Not Available. System running in CPU mode.\")\n",
    "except Exception as e:\n",
    "    print(f\"\ud83d\udd34 CUDA Check Failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pipeline Test \ud83d\udec0\n",
    "Validate loading of a single data file (.dbn.zst or .parquet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.orchestrator import get_data_source\n",
    "from tests.utils import get_test_data_files\n",
    "\n",
    "try:\n",
    "    files = get_test_data_files()\n",
    "    if not files:\n",
    "        print(\"\ud83d\udd34 No data files found.\")\n",
    "    else:\n",
    "        test_file = files[0]\n",
    "        print(f\"Loading {os.path.basename(test_file)}...\")\n",
    "        df = get_data_source(test_file)\n",
    "        print(f\"\ud83d\udfe2 Load Success! Shape: {df.shape}\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Store for later use\n",
    "        sample_data = df.head(1000).copy() if len(df) > 1000 else df.copy()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\ud83d\udd34 Pipeline Test Failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Core Component Tests \u2699\ufe0f\n",
    "Verify StateVector, BayesianBrain, LayerEngine, and CUDA modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.state_vector import StateVector\n",
    "from core.bayesian_brain import BayesianBrain\n",
    "from core.layer_engine import LayerEngine\n",
    "\n",
    "print(\"--- Component Status ---\")\n",
    "\n",
    "# 1. StateVector\n",
    "try:\n",
    "    sv = StateVector.null_state()\n",
    "    assert hash(sv) is not None\n",
    "    print(\"\ud83d\udfe2 StateVector: Operational\")\n",
    "except Exception as e:\n",
    "    print(f\"\ud83d\udd34 StateVector: Failed ({e})\")\n",
    "\n",
    "# 2. BayesianBrain\n",
    "try:\n",
    "    bb = BayesianBrain()\n",
    "    print(\"\ud83d\udfe2 BayesianBrain: Initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"\ud83d\udd34 BayesianBrain: Failed ({e})\")\n",
    "\n",
    "# 3. LayerEngine\n",
    "try:\n",
    "    le = LayerEngine(use_gpu=cuda.is_available() if 'cuda' in locals() else False)\n",
    "    print(f\"\ud83d\udfe2 LayerEngine: Initialized (GPU={le.use_gpu})\")\n",
    "except Exception as e:\n",
    "    print(f\"\ud83d\udd34 LayerEngine: Failed ({e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mini Training Run (5 Iterations) \ud83c\udfc3\u200d\u2642\ufe0f\n",
    "Interactive 5-iteration training on sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.orchestrator import TrainingOrchestrator\n",
    "\n",
    "def run_mini_training(b):\n",
    "    with out_area:\n",
    "        clear_output()\n",
    "        print(\"Initializing Mini Training (5 iterations)...\")\n",
    "        \n",
    "        if 'sample_data' not in globals():\n",
    "            print(\"\ud83d\udd34 Sample data not loaded. Run Section 2 first.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Determine GPU usage dynamically\n",
    "            use_gpu = False\n",
    "            try:\n",
    "                use_gpu = cuda.is_available()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            orch = TrainingOrchestrator(\n",
    "                asset_ticker='MNQ', \n",
    "                data=sample_data, \n",
    "                output_dir='debug_outputs/mini_run',\n",
    "                use_gpu=use_gpu,\n",
    "                verbose=chk_verbose.value\n",
    "            )\n",
    "            \n",
    "            res = orch.run_training(iterations=5)\n",
    "            print(\"\\n\ud83d\udfe2 Mini Run Complete!\")\n",
    "            print(f\"Total Trades: {res['total_trades']}\")\n",
    "            print(f\"PnL: ${res['pnl']:.2f}\")\n",
    "            print(f\"Win Rate: {res['win_rate']:.1%}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\ud83d\udd34 Training Failed: {e}\")\n",
    "\n",
    "chk_verbose = widgets.Checkbox(value=False, description='Verbose Mode')\n",
    "btn_run = widgets.Button(description=\"Run 5 Iterations\", button_style='primary')\n",
    "out_area = widgets.Output()\n",
    "\n",
    "btn_run.on_click(run_mini_training)\n",
    "display(widgets.VBox([widgets.HBox([btn_run, chk_verbose]), out_area]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Probability Table Analysis \ud83d\udcca\n",
    "Analyze the learned probability tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_and_analyze_table(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"File not found: {path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Loading {path}...\")\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        # Handle both raw dict and BayesianBrain object\n",
    "        table = data['table'] if isinstance(data, dict) and 'table' in data else getattr(data, 'table', {})\n",
    "        \n",
    "        print(f\"Total States: {len(table)}\")\n",
    "        \n",
    "        # Convert to DF\n",
    "        records = []\n",
    "        for state, stats in table.items():\n",
    "            total = stats['total']\n",
    "            wins = stats['wins']\n",
    "            if total > 0:\n",
    "                records.append({\n",
    "                    'state_hash': hash(state),\n",
    "                    'total': total,\n",
    "                    'wins': wins,\n",
    "                    'win_rate': wins/total,\n",
    "                    'L1': state.L1_bias,\n",
    "                    'L5': state.L5_trend\n",
    "                })\n",
    "        \n",
    "        if records:\n",
    "            df_stats = pd.DataFrame(records)\n",
    "            print(\"\\nTop 5 States by Sample Size:\")\n",
    "            display(df_stats.sort_values('total', ascending=False).head())\n",
    "            \n",
    "            fig = px.scatter(df_stats, x='total', y='win_rate', \n",
    "                             color='L1', title='Win Rate vs Sample Size',\n",
    "                             hover_data=['L5'])\n",
    "            fig.show()\n",
    "        else:\n",
    "            print(\"No valid states found.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing table: {e}\")\n",
    "\n",
    "btn_analyze = widgets.Button(description=\"Analyze Mini-Run Model\")\n",
    "btn_analyze.on_click(lambda b: load_and_analyze_table('debug_outputs/mini_run/probability_table.pkl'))\n",
    "display(btn_analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Profiling \u23f1\ufe0f\n",
    "Benchmark state hashing and component latencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "print(\"Benchmarking StateVector Hashing...\")\n",
    "setup_code = \"from core.state_vector import StateVector; sv = StateVector.null_state()\"\n",
    "t = timeit.timeit(\"hash(sv)\", setup=setup_code, number=100000)\n",
    "print(f\"Create & Hash 100k states: {t:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. DOE Simulation Preview \ud83e\uddea\n",
    "Visualize parameter combinations for future optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "param_grid = {\n",
    "    'min_prob': [0.70, 0.75, 0.80, 0.85],\n",
    "    'min_conf': [0.20, 0.30, 0.40],\n",
    "    'stop_loss': [10, 20, 30],\n",
    "    'kill_zones': ['tight', 'wide']\n",
    "}\n",
    "keys, values = zip(*param_grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "print(f\"Total Parameter Combinations: {len(combinations)}\")\n",
    "\n",
    "print(\"Sample Combinations:\")\n",
    "for c in combinations[:5]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quick Fixes & Utilities \ud83d\udee0\ufe0f\n",
    "Common maintenance tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def clean_pycache():\n",
    "    print(\"Cleaning __pycache__...\")\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk('.'):\n",
    "        for d in dirs:\n",
    "            if d == '__pycache__':\n",
    "                shutil.rmtree(os.path.join(root, d))\n",
    "                count += 1\n",
    "    print(f\"Removed {count} directories.\")\n",
    "\n",
    "btn_clean = widgets.Button(description=\"Clear PyCache\")\n",
    "btn_clean.on_click(lambda b: clean_pycache())\n",
    "display(btn_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}